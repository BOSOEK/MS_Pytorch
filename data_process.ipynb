{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cab17a-e484-4490-9b3f-cf4bffa6a6df",
   "metadata": {},
   "source": [
    "# 데이터 로드\n",
    "\n",
    "파이토치는 ```torch.tuils.data.DataLoader``` 와 ```torch.utils.data.Dataset``` 두개의 데이터 프리미티브를 제공한다.\n",
    "\n",
    "### 하이퍼 파라미터\n",
    "* ```Iteration``` : 미니 배치를 이용해 학습하는 횟수\n",
    "* ```Mini_Batch``` : 데이터 학습시 한번에 학습할 데이터의 양\n",
    "* ```EPOCHS``` : 전체 데이터로 학습한 횟수\n",
    "* ```BATCH_SIZE``` : MLP 모델을 학습할 때 필요한 데이터 개수\n",
    "\n",
    "### Dataset : 데이터를 불러올 때 사용\n",
    "* ```root``` : 데이터가 저장되는 경로\n",
    "* ```train``` : 데이터가 테스트용인지 훈련 용인지를 결정합니다\n",
    "* ```download``` : 인터넷에서 다운로드할 것인지 결정\n",
    "* ```transform``` : 데이터 전처리 지정(transforms.ToTensor() 지정시 텐서 형태로 변경하고 정규화를 할 수 있다)\n",
    "\n",
    "### DataLoader : 데이터를 미니 배치 단위로 분리해 지정\n",
    "* ```dataset``` : 미니 배치 단위로 할당하고자 하는 데이터셋 지정 train_dataset/test_dataset\n",
    "* ```batch_size``` : 미니배치 1개를 구성하는 데이터 개수\n",
    "* ```shuffle``` : 데이터를 섞을 것인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35970ed-6c9d-416f-b562-ef5cc7e572c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\download\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1cf069-6cfb-4158-98b0-cc3368242bd4",
   "metadata": {},
   "source": [
    "### 파일에 대한 맞춤 데이터 셑 만들기\n",
    "데이터 집합 클래스는 세기능을 구현해야 한다 `__init__`, `__len__`, `__getitem__`이다.\n",
    "* `__init__` : 데이터 셋 개체를 인스턴스화 할때 한번만 실행된다. __이미지, 주석, 파일 및 디렉터리 초기화__ 등\n",
    "* `__len__` : 데이터 세트의 __샘플 수__ 반환\n",
    "* `__getitem__` : 주어진 인덱스에 있는 데이터 세트에서 샘플을 로드하고 반환. 인덱스를 기반으로 이미지 위치를 식별하고 사용하여 텐서로 변환하고 텐서 이미지와 해당 레이블 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a805a8-25bf-475b-af77-557a69d2a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.io as tvio\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_lables = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_lables)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = tvio.read_image(img_path)\n",
    "        lable = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(lable)\n",
    "        sample = {\"image\" : image, \"label\" : label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2916ece7-0c81-48c4-a03b-167d9b3ee90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lable : 9\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Lable : {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b572d2f-f5df-481e-ab2c-5ecffe377e7f",
   "metadata": {},
   "source": [
    "### 변형\n",
    "데이터는 언제가 최종 처리가 아니기 때문에 **변환**을 해야한다.   \n",
    "훈련을 위해 **정규화 된 텐서**로 원-핫 인코딩 된 레이블이 필요하며 이때 쓰이는 것이 `ToTensor`, `Lambda`이다\n",
    "* `ToTensor` : 이미지나 넘파이 배열을 `Floattensor`로 변환하고 0~1 범위에서 픽셀 강고 값 조정\n",
    "* `Lambda` : 사용자 정의 람다 함수로 직접 텐서로 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e732ed-04f1-4ce8-8bd2-3a7ca6803597",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c7097-f238-4262-8222-10194be2ad63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
